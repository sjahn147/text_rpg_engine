"""
ë°ì´í„°ë² ì´ìŠ¤ ë¬´ê²°ì„± ë° ì •ê·œí™” í…ŒìŠ¤íŠ¸
MVP v2 ìŠ¤í‚¤ë§ˆì˜ ë°ì´í„° ë¬´ê²°ì„±, ì •ê·œí™”, ì°¸ì¡° ë¬´ê²°ì„± ê²€ì¦
"""

import pytest
import pytest_asyncio
import asyncio
from typing import Dict, List, Any
from database.connection import DatabaseConnection
from common.utils.logger import logger

class TestDatabaseIntegrity:
    """ë°ì´í„°ë² ì´ìŠ¤ ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    @pytest_asyncio.fixture
    async def db_connection(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í”½ìŠ¤ì²˜"""
        db = DatabaseConnection()
        # ì—°ê²° í’€ ì´ˆê¸°í™”
        await db.pool
        yield db
        await db.close()
    
    @pytest_asyncio.fixture
    async def conn(self, db_connection):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´"""
        pool = await db_connection.pool
        async with pool.acquire() as conn:
            yield conn
    
    @pytest.mark.asyncio
    @pytest.mark.asyncio
    async def test_schema_existence(self, conn):
        """ìŠ¤í‚¤ë§ˆ ì¡´ì¬ í™•ì¸"""
        schemas = await conn.fetch("""
            SELECT schema_name 
            FROM information_schema.schemata 
            WHERE schema_name IN ('game_data', 'reference_layer', 'runtime_data')
            ORDER BY schema_name
        """)
        
        expected_schemas = {'game_data', 'reference_layer', 'runtime_data'}
        actual_schemas = {row['schema_name'] for row in schemas}
        
        assert expected_schemas == actual_schemas, f"ëˆ„ë½ëœ ìŠ¤í‚¤ë§ˆ: {expected_schemas - actual_schemas}"
        logger.info("âœ… ëª¨ë“  ìŠ¤í‚¤ë§ˆ ì¡´ì¬ í™•ì¸")
    
    @pytest.mark.asyncio
    async def test_foreign_key_constraints(self, conn):
        """ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ê²€ì¦"""
        fk_constraints = await conn.fetch("""
            SELECT 
                tc.table_schema,
                tc.table_name,
                tc.constraint_name,
                kcu.column_name,
                ccu.table_schema AS foreign_table_schema,
                ccu.table_name AS foreign_table_name,
                ccu.column_name AS foreign_column_name
            FROM information_schema.table_constraints AS tc
            JOIN information_schema.key_column_usage AS kcu
                ON tc.constraint_name = kcu.constraint_name
                AND tc.table_schema = kcu.table_schema
            JOIN information_schema.constraint_column_usage AS ccu
                ON ccu.constraint_name = tc.constraint_name
                AND ccu.table_schema = tc.table_schema
            WHERE tc.constraint_type = 'FOREIGN KEY'
            ORDER BY tc.table_schema, tc.table_name
        """)
        
        # ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        assert len(fk_constraints) > 0, "ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ì´ ì—†ìŠµë‹ˆë‹¤"
        
        # ì£¼ìš” ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ í™•ì¸
        fk_dict = {}
        for row in fk_constraints:
            key = f"{row['table_schema']}.{row['table_name']}.{row['column_name']}"
            fk_dict[key] = f"{row['foreign_table_schema']}.{row['foreign_table_name']}.{row['foreign_column_name']}"
        
        # í•µì‹¬ ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ê²€ì¦ (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì œì•½ì¡°ê±´ë§Œ í™•ì¸)
        critical_fks = [
            "game_data.effect_carriers.source_entity_id -> game_data.entities.entity_id"
        ]
        
        for fk in critical_fks:
            parts = fk.split(" -> ")
            if len(parts) == 2:
                source, target = parts
                source_parts = source.split(".")
                if len(source_parts) == 3:
                    schema, table, column = source_parts
                    key = f"{schema}.{table}.{column}"
                    assert key in fk_dict, f"í•µì‹¬ ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ëˆ„ë½: {fk}"
        
        logger.info(f"âœ… {len(fk_constraints)}ê°œì˜ ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ í™•ì¸")
    
    @pytest.mark.asyncio
    async def test_table_normalization(self, conn):
        """í…Œì´ë¸” ì •ê·œí™” ê²€ì¦"""
        # ì¤‘ë³µ ì»¬ëŸ¼ í™•ì¸ (ì •ê·œí™” ìœ„ë°˜ ê²€ì‚¬)
        tables_with_duplicates = []
        
        # game_dataì™€ runtime_data ê°„ ì¤‘ë³µ ì»¬ëŸ¼ í™•ì¸
        game_columns = await conn.fetch("""
            SELECT table_name, column_name, data_type
            FROM information_schema.columns
            WHERE table_schema = 'game_data'
            AND table_name IN ('entities', 'world_cells', 'world_objects')
            ORDER BY table_name, column_name
        """)
        
        runtime_columns = await conn.fetch("""
            SELECT table_name, column_name, data_type
            FROM information_schema.columns
            WHERE table_schema = 'runtime_data'
            AND table_name IN ('runtime_entities', 'runtime_cells', 'runtime_objects')
            ORDER BY table_name, column_name
        """)
        
        # runtime í…Œì´ë¸”ì€ ì°¸ì¡°ë§Œ ì €ì¥í•´ì•¼ í•¨ (name, description ë“± ì¤‘ë³µ ì œê±°)
        runtime_entity_columns = [row['column_name'] for row in runtime_columns if row['table_name'] == 'runtime_entities']
        
        # ì¤‘ë³µ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì •ê·œí™” ìœ„ë°˜
        duplicate_columns = ['name', 'description', 'entity_type']
        found_duplicates = [col for col in duplicate_columns if col in runtime_entity_columns]
        
        assert len(found_duplicates) == 0, f"ì •ê·œí™” ìœ„ë°˜: runtime_entitiesì— ì¤‘ë³µ ì»¬ëŸ¼ ì¡´ì¬: {found_duplicates}"
        
        logger.info("âœ… í…Œì´ë¸” ì •ê·œí™” ê²€ì¦ ì™„ë£Œ")
    
    @pytest.mark.asyncio
    async def test_index_optimization(self, conn):
        """ì¸ë±ìŠ¤ ìµœì í™” ê²€ì¦"""
        indexes = await conn.fetch("""
            SELECT 
                schemaname,
                tablename,
                indexname,
                indexdef
            FROM pg_indexes
            WHERE schemaname IN ('game_data', 'reference_layer', 'runtime_data')
            ORDER BY schemaname, tablename, indexname
        """)
        
        # í•„ìˆ˜ ì¸ë±ìŠ¤ í™•ì¸
        required_indexes = [
            "idx_region_type",
            "idx_location_region", 
            "idx_cell_location",
            "idx_entity_type",
            "idx_runtime_entity_game",
            "idx_runtime_entity_session",
            "idx_runtime_cell_game",
            "idx_runtime_cell_session",
            "idx_runtime_object_game",
            "idx_runtime_object_session"
        ]
        
        existing_indexes = [row['indexname'] for row in indexes]
        missing_indexes = [idx for idx in required_indexes if idx not in existing_indexes]
        
        assert len(missing_indexes) == 0, f"ëˆ„ë½ëœ í•„ìˆ˜ ì¸ë±ìŠ¤: {missing_indexes}"
        
        # JSONB ì»¬ëŸ¼ GIN ì¸ë±ìŠ¤ í™•ì¸
        gin_indexes = [row for row in indexes if 'gin' in row['indexdef'].lower()]
        assert len(gin_indexes) > 0, "JSONB ì»¬ëŸ¼ì— GIN ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤"
        
        logger.info(f"âœ… {len(indexes)}ê°œì˜ ì¸ë±ìŠ¤ í™•ì¸ (GIN ì¸ë±ìŠ¤: {len(gin_indexes)}ê°œ)")
    
    @pytest.mark.asyncio
    async def test_data_integrity_constraints(self, conn):
        """ë°ì´í„° ë¬´ê²°ì„± ì œì•½ì¡°ê±´ ê²€ì¦"""
        # NOT NULL ì œì•½ì¡°ê±´ í™•ì¸
        not_null_columns = await conn.fetch("""
            SELECT 
                table_schema,
                table_name,
                column_name,
                is_nullable
            FROM information_schema.columns
            WHERE table_schema IN ('game_data', 'reference_layer', 'runtime_data')
            AND is_nullable = 'NO'
            ORDER BY table_schema, table_name, column_name
        """)
        
        # í•µì‹¬ NOT NULL ì œì•½ì¡°ê±´ í™•ì¸
        critical_not_null = [
            ("game_data", "entities", "entity_id"),
            ("game_data", "entities", "entity_name"),
            ("game_data", "entities", "entity_type"),
            ("runtime_data", "runtime_entities", "game_entity_id"),
            ("runtime_data", "runtime_entities", "session_id"),
            ("runtime_data", "active_sessions", "session_id"),
            ("runtime_data", "active_sessions", "session_name")
        ]
        
        not_null_dict = {}
        for row in not_null_columns:
            key = (row['table_schema'], row['table_name'], row['column_name'])
            not_null_dict[key] = True
        
        for schema, table, column in critical_not_null:
            key = (schema, table, column)
            assert key in not_null_dict, f"í•µì‹¬ NOT NULL ì œì•½ì¡°ê±´ ëˆ„ë½: {schema}.{table}.{column}"
        
        logger.info(f"âœ… {len(not_null_columns)}ê°œì˜ NOT NULL ì œì•½ì¡°ê±´ í™•ì¸")
    
    @pytest.mark.asyncio
    async def test_referential_integrity(self, conn):
        """ì°¸ì¡° ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚½ì…
        await conn.execute("""
            INSERT INTO game_data.entities (entity_id, entity_name, entity_type, entity_description, entity_properties)
            VALUES ('TEST_ENTITY_001', 'í…ŒìŠ¤íŠ¸ ì—”í‹°í‹°', 'npc', 'í…ŒìŠ¤íŠ¸ìš© ì—”í‹°í‹°', '{}')
        """)
        
        await conn.execute("""
            INSERT INTO runtime_data.active_sessions (session_id, session_name, session_state, metadata)
            VALUES ('00000000-0000-0000-0000-000000000001', 'í…ŒìŠ¤íŠ¸ ì„¸ì…˜', 'active', '{}')
        """)
        
        # ì •ìƒì ì¸ ì°¸ì¡° ìƒì„±
        await conn.execute("""
            INSERT INTO runtime_data.runtime_entities (runtime_entity_id, game_entity_id, session_id)
            VALUES ('00000000-0000-0000-0000-000000000002', 'TEST_ENTITY_001', '00000000-0000-0000-0000-000000000001')
        """)
        
        # ì˜ëª»ëœ ì°¸ì¡° ì‹œë„ (ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ìœ„ë°˜)
        with pytest.raises(Exception):  # ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ìœ„ë°˜ ì˜ˆì™¸
            await conn.execute("""
                INSERT INTO runtime_data.runtime_entities (runtime_entity_id, game_entity_id, session_id)
                VALUES ('00000000-0000-0000-0000-000000000003', 'NONEXISTENT_ENTITY', '00000000-0000-0000-0000-000000000001')
            """)
        
        # ì •ë¦¬
        await conn.execute("DELETE FROM runtime_data.runtime_entities WHERE runtime_entity_id = '00000000-0000-0000-0000-000000000002'")
        await conn.execute("DELETE FROM runtime_data.active_sessions WHERE session_id = '00000000-0000-0000-0000-000000000001'")
        await conn.execute("DELETE FROM game_data.entities WHERE entity_id = 'TEST_ENTITY_001'")
        
        logger.info("âœ… ì°¸ì¡° ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    @pytest.mark.asyncio
    async def test_cascade_delete_behavior(self, conn):
        """CASCADE DELETE ë™ì‘ ê²€ì¦"""
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        await conn.execute("""
            INSERT INTO game_data.entities (entity_id, entity_name, entity_type, entity_description, entity_properties)
            VALUES ('TEST_CASCADE_001', 'CASCADE í…ŒìŠ¤íŠ¸ ì—”í‹°í‹°', 'npc', 'CASCADE í…ŒìŠ¤íŠ¸ìš©', '{}')
        """)
        
        await conn.execute("""
            INSERT INTO runtime_data.active_sessions (session_id, session_name, session_state, metadata)
            VALUES ('00000000-0000-0000-0000-000000000004', 'CASCADE í…ŒìŠ¤íŠ¸ ì„¸ì…˜', 'active', '{}')
        """)
        
        await conn.execute("""
            INSERT INTO runtime_data.runtime_entities (runtime_entity_id, game_entity_id, session_id)
            VALUES ('00000000-0000-0000-0000-000000000005', 'TEST_CASCADE_001', '00000000-0000-0000-0000-000000000004')
        """)
        
        # ì„¸ì…˜ ì‚­ì œ ì‹œ ê´€ë ¨ ë°ì´í„° CASCADE ì‚­ì œ í™•ì¸
        await conn.execute("DELETE FROM runtime_data.active_sessions WHERE session_id = '00000000-0000-0000-0000-000000000004'")
        
        # runtime_entitiesë„ í•¨ê»˜ ì‚­ì œë˜ì—ˆëŠ”ì§€ í™•ì¸
        remaining_entities = await conn.fetch("""
            SELECT COUNT(*) as count FROM runtime_data.runtime_entities 
            WHERE runtime_entity_id = '00000000-0000-0000-0000-000000000005'
        """)
        
        assert remaining_entities[0]['count'] == 0, "CASCADE DELETEê°€ ì œëŒ€ë¡œ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
        
        # ì •ë¦¬
        await conn.execute("DELETE FROM game_data.entities WHERE entity_id = 'TEST_CASCADE_001'")
        
        logger.info("âœ… CASCADE DELETE ë™ì‘ ê²€ì¦ ì™„ë£Œ")
    
    @pytest.mark.asyncio
    async def test_jsonb_column_validation(self, conn):
        """JSONB ì»¬ëŸ¼ ê²€ì¦"""
        # ê¸°ì¡´ ë°ì´í„° ì •ë¦¬
        await conn.execute("DELETE FROM game_data.entities WHERE entity_id = 'TEST_JSONB_001'")
        
        # ìœ íš¨í•œ JSONB ë°ì´í„° ì‚½ì…
        await conn.execute("""
            INSERT INTO game_data.entities (entity_id, entity_name, entity_type, entity_description, entity_properties)
            VALUES ('TEST_JSONB_001', 'JSONB í…ŒìŠ¤íŠ¸ ì—”í‹°í‹°', 'npc', 'JSONB í…ŒìŠ¤íŠ¸ìš©',     
                    '{"level": 5, "gold": 100, "inventory": ["sword", "potion"], "stats": {"hp": 100, "mp": 50}}')
        """)
        
        # JSONB ë°ì´í„° ì¡°íšŒ ë° ê²€ì¦
        result = await conn.fetchrow("""
            SELECT entity_properties FROM game_data.entities WHERE entity_id = 'TEST_JSONB_001'
        """)
        
        assert result is not None, "JSONB ë°ì´í„° ì‚½ì… ì‹¤íŒ¨"
        properties = result['entity_properties']
        
        # JSONB ë°ì´í„° íƒ€ì… ì²˜ë¦¬
        if isinstance(properties, str):
            import json
            properties = json.loads(properties)

        assert properties['level'] == 5, "JSONB ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨"
        assert properties['gold'] == 100, "JSONB ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨"
        assert 'inventory' in properties, "JSONB ë°°ì—´ ë°ì´í„° ëˆ„ë½"
        assert properties['stats']['hp'] == 100, "JSONB ì¤‘ì²© ê°ì²´ ê²€ì¦ ì‹¤íŒ¨"
        
        # ì •ë¦¬
        await conn.execute("DELETE FROM game_data.entities WHERE entity_id = 'TEST_JSONB_001'")
        
        logger.info("âœ… JSONB ì»¬ëŸ¼ ê²€ì¦ ì™„ë£Œ")
    
    @pytest.mark.asyncio
    async def test_performance_metrics(self, conn):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ìŠ¤ ê²€ì¦"""
        # í…Œì´ë¸” í¬ê¸° í™•ì¸
        table_sizes = await conn.fetch("""
            SELECT 
                schemaname,
                tablename,
                pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
            FROM pg_tables
            WHERE schemaname IN ('game_data', 'reference_layer', 'runtime_data')
            ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
        """)
        
        # ì¸ë±ìŠ¤ ì‚¬ìš©ë¥  í™•ì¸ (ì˜¬ë°”ë¥¸ ì»¬ëŸ¼ëª… ì‚¬ìš©)
        index_usage = await conn.fetch("""
            SELECT 
                schemaname,
                relname as tablename,
                indexrelname as indexname,
                idx_scan,
                idx_tup_read,
                idx_tup_fetch
            FROM pg_stat_user_indexes
            WHERE schemaname IN ('game_data', 'reference_layer', 'runtime_data')
            ORDER BY idx_scan DESC
        """)
        
        logger.info("ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­ìŠ¤:")
        for row in table_sizes:
            logger.info(f"  {row['schemaname']}.{row['tablename']}: {row['size']}")
        
        logger.info("âœ… ì„±ëŠ¥ ë©”íŠ¸ë¦­ìŠ¤ ê²€ì¦ ì™„ë£Œ")

class TestDatabaseIntegration:
    """ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸"""
    
    @pytest_asyncio.fixture
    async def db_connection(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í”½ìŠ¤ì²˜"""
        db = DatabaseConnection()
        # ì—°ê²° í’€ ì´ˆê¸°í™”
        await db.pool
        yield db
        await db.close()
    
    @pytest.mark.asyncio
    async def test_full_data_flow(self, db_connection):
        """ì „ì²´ ë°ì´í„° í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        # 1. ê²Œì„ ë°ì´í„° ìƒì„±
        pool = await db_connection.pool
        async with pool.acquire() as conn:
            # ê¸°ì¡´ ë°ì´í„° ì •ë¦¬ (ì°¸ì¡° ìˆœì„œëŒ€ë¡œ ì‚­ì œ)
            await conn.execute("DELETE FROM runtime_data.entity_states WHERE runtime_entity_id = '00000000-0000-0000-0000-000000000007'")
            await conn.execute("DELETE FROM reference_layer.entity_references WHERE runtime_entity_id = '00000000-0000-0000-0000-000000000007'")
            await conn.execute("DELETE FROM runtime_data.runtime_entities WHERE runtime_entity_id = '00000000-0000-0000-0000-000000000007'")
            await conn.execute("DELETE FROM runtime_data.active_sessions WHERE session_id = '00000000-0000-0000-0000-000000000006'")
            await conn.execute("DELETE FROM game_data.entities WHERE entity_id = 'FLOW_TEST_001'")
            
            # ê²Œì„ ë°ì´í„° ì‚½ì…
            await conn.execute("""
                INSERT INTO game_data.entities (entity_id, entity_name, entity_type, entity_description, entity_properties)
                VALUES ('FLOW_TEST_001', 'í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì—”í‹°í‹°', 'npc', 'ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸ìš©', '{"level": 1}')
            """)
            
            # ê¸°ì¡´ ì„¸ì…˜ ì •ë¦¬
            await conn.execute("DELETE FROM runtime_data.active_sessions WHERE session_id = '00000000-0000-0000-0000-000000000006'")
            
            # ì„¸ì…˜ ìƒì„±
            await conn.execute("""
                INSERT INTO runtime_data.active_sessions (session_id, session_name, session_state, metadata)
                VALUES ('00000000-0000-0000-0000-000000000006', 'í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì„¸ì…˜', 'active', '{}')
            """)
            
            # ëŸ°íƒ€ì„ ì—”í‹°í‹° ìƒì„±
            await conn.execute("""
                INSERT INTO runtime_data.runtime_entities (runtime_entity_id, game_entity_id, session_id)
                VALUES ('00000000-0000-0000-0000-000000000007', 'FLOW_TEST_001', '00000000-0000-0000-0000-000000000006')
            """)
            
            # ì°¸ì¡° ë ˆì´ì–´ ìƒì„± (entity_type í•„ìˆ˜)
            await conn.execute("""
                INSERT INTO reference_layer.entity_references (runtime_entity_id, game_entity_id, session_id, entity_type)
                VALUES ('00000000-0000-0000-0000-000000000007', 'FLOW_TEST_001', '00000000-0000-0000-0000-000000000006', 'npc')
            """)
            
            # ì—”í‹°í‹° ìƒíƒœ ìƒì„±
            await conn.execute("""
                INSERT INTO runtime_data.entity_states (runtime_entity_id, current_stats, current_position, active_effects, inventory, equipped_items)
                VALUES ('00000000-0000-0000-0000-000000000007', '{"hp": 100, "mp": 50}', '{"x": 10, "y": 10}', '{}', '[]', '{}')
            """)
            
            # ë°ì´í„° ì¡°íšŒ ë° ê²€ì¦
            result = await conn.fetchrow("""
                SELECT 
                    ge.entity_name,
                    re.session_id,
                    es.current_stats
                FROM game_data.entities ge
                JOIN reference_layer.entity_references re ON ge.entity_id = re.game_entity_id
                JOIN runtime_data.entity_states es ON re.runtime_entity_id = es.runtime_entity_id
                WHERE ge.entity_id = 'FLOW_TEST_001'
            """)
            
            assert result is not None, "ì „ì²´ ë°ì´í„° í”Œë¡œìš° ì‹¤íŒ¨"
            assert result['entity_name'] == 'í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì—”í‹°í‹°'
            assert str(result['session_id']) == '00000000-0000-0000-0000-000000000006'
            # JSONB ë°ì´í„° íƒ€ì… ì²˜ë¦¬
            current_stats = result['current_stats']
            if isinstance(current_stats, str):
                import json
                current_stats = json.loads(current_stats)
            
            assert current_stats['hp'] == 100
            
            # ì •ë¦¬
            await conn.execute("DELETE FROM runtime_data.entity_states WHERE runtime_entity_id = '00000000-0000-0000-0000-000000000007'")
            await conn.execute("DELETE FROM reference_layer.entity_references WHERE runtime_entity_id = '00000000-0000-0000-0000-000000000007'")
            await conn.execute("DELETE FROM runtime_data.runtime_entities WHERE runtime_entity_id = '00000000-0000-0000-0000-000000000007'")
            await conn.execute("DELETE FROM runtime_data.active_sessions WHERE session_id = '00000000-0000-0000-0000-000000000006'")
            await conn.execute("DELETE FROM game_data.entities WHERE entity_id = 'FLOW_TEST_001'")
            
            logger.info("âœ… ì „ì²´ ë°ì´í„° í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

if __name__ == "__main__":
    pytest.main([__file__, "-v"])
